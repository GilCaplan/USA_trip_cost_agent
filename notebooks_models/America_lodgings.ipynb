{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec5ab4b0-c50b-446c-9524-5803dd6493b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Airbnb Loaded: 2098880 rows\nBooking Loaded: 3239391 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup Configuration\n",
    "storage_account = \"\"\n",
    "storage_account = \"\"\n",
    "container_airbnb = \"airbnb\"\n",
    "container_booking = \"booking\"\n",
    "# New SAS tokens provided in the update\n",
    "airbnb_sas = \"\"\n",
    "booking_sas = \"\"\n",
    "\n",
    "# Helper function to inject the token\n",
    "def set_spark_token(token):\n",
    "    spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"SAS\")\n",
    "    spark.conf.set(f\"fs.azure.sas.token.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "    spark.conf.set(f\"fs.azure.sas.fixed.token.{storage_account}.dfs.core.windows.net\", token)\n",
    "\n",
    "# --- LOAD AIRBNB DATA ---\n",
    "set_spark_token(airbnb_sas)\n",
    "# Using abfss:// protocol to match the dfs.core.windows.net config\n",
    "airbnb_path = f\"abfss://airbnb@{storage_account}.dfs.core.windows.net/airbnb_1_12_parquet\"\n",
    "airbnb_df = spark.read.parquet(airbnb_path)\n",
    "print(f\"Airbnb Loaded: {airbnb_df.count()} rows\")\n",
    "\n",
    "# --- LOAD BOOKING DATA ---\n",
    "# We must overwrite the config with the Booking token to access the second container\n",
    "set_spark_token(booking_sas)\n",
    "# Assuming the file structure matches Airbnb. If this fails, check the exact folder name in the repo.\n",
    "fname = \"booking_1_9.parquet\" \n",
    "booking_path = f\"abfss://{container_booking}@{storage_account}.dfs.core.windows.net/{fname}\"\n",
    "booking_df = spark.read.parquet(booking_path)\n",
    "print(f\"Booking Loaded: {booking_df.count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d242cfc-1576-41b9-8453-ff630459f4f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Booking.com Schema ===\nroot\n |-- availability: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- bed_configuration: string (nullable = true)\n |    |    |-- max_number_of guests: string (nullable = true)\n |    |    |-- max_number_of_guests: long (nullable = true)\n |    |    |-- room_type: string (nullable = true)\n |-- city: string (nullable = true)\n |-- coordinates: struct (nullable = true)\n |    |-- lan: double (nullable = true)\n |    |-- lon: double (nullable = true)\n |-- country: string (nullable = true)\n |-- description: string (nullable = true)\n |-- fine_print: string (nullable = true)\n |-- hotel_id: string (nullable = true)\n |-- house_rules: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- description: string (nullable = true)\n |    |    |-- rule: string (nullable = true)\n |-- images: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- location: string (nullable = true)\n |-- managed_by: string (nullable = true)\n |-- manager_language_spoken: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- manager_score: double (nullable = true)\n |-- metro_railway_access: boolean (nullable = true)\n |-- most_popular_facilities: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- number_of_reviews: long (nullable = true)\n |-- popular_facilities: struct (nullable = true)\n |    |-- facility: string (nullable = true)\n |    |-- services: array (nullable = true)\n |    |    |-- element: string (containsNull = true)\n |-- property_highlights: string (nullable = true)\n |-- property_information: string (nullable = true)\n |-- property_surroundings: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- distance: double (nullable = true)\n |    |    |-- distance_unit: string (nullable = true)\n |    |    |-- location_name: string (nullable = true)\n |-- review_score: double (nullable = true)\n |-- reviews_scores: struct (nullable = true)\n |    |-- category: string (nullable = true)\n |    |-- score: string (nullable = true)\n |-- title: string (nullable = true)\n |-- top_reviews: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- location: string (nullable = true)\n |    |    |-- review: string (nullable = true)\n |    |    |-- reviewer_name: string (nullable = true)\n |-- url: string (nullable = true)\n\n\nDetected Filtering Column: 'country'\nFiltered Row Count: 33906\n\nSUCCESS! File saved at:\ndbfs:/Workspace/Users/gil.caplan@campus.technion.ac.il/Lodging_data/booking_usa_FINAL.parquet\n\nSample Data:\n+-------------+\n|country      |\n+-------------+\n|United States|\n|United States|\n|United States|\n|United States|\n|United States|\n+-------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower\n",
    "import os\n",
    "\n",
    "# --- 1. SETUP CONFIGURATION ---\n",
    "storage_account = \"\"\n",
    "# Booking SAS Token (Different from Airbnb!)\n",
    "booking_sas = \"\"\n",
    "\n",
    "def set_booking_token():\n",
    "    spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"SAS\")\n",
    "    spark.conf.set(f\"fs.azure.sas.token.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "    spark.conf.set(f\"fs.azure.sas.fixed.token.{storage_account}.dfs.core.windows.net\", booking_sas)\n",
    "\n",
    "# Apply Token\n",
    "set_booking_token()\n",
    "\n",
    "# --- 2. LOAD DATA ---\n",
    "# Using the filename 'booking_1_9.parquet' from your previous successful attempt\n",
    "booking_path = f\"abfss://booking@{storage_account}.dfs.core.windows.net/booking_1_9.parquet\"\n",
    "df_booking = spark.read.parquet(booking_path)\n",
    "\n",
    "print(\"=== Booking.com Schema ===\")\n",
    "df_booking.printSchema()\n",
    "\n",
    "# --- 3. IDENTIFY LOCATION COLUMN ---\n",
    "# We check for likely column names automatically\n",
    "columns = [c.lower() for c in df_booking.columns]\n",
    "target_col = None\n",
    "\n",
    "if \"address\" in columns:\n",
    "    target_col = \"address\"\n",
    "elif \"hotel_address\" in columns:\n",
    "    target_col = \"hotel_address\"\n",
    "elif \"country\" in columns:\n",
    "    target_col = \"country\"\n",
    "elif \"location\" in columns:\n",
    "    target_col = \"location\"\n",
    "\n",
    "print(f\"\\nDetected Filtering Column: '{target_col}'\")\n",
    "\n",
    "# --- 4. FILTER & SAVE ---\n",
    "if target_col:\n",
    "    # Robust filter for US/USA/United States\n",
    "    df_usa_booking = df_booking.filter(\n",
    "        lower(col(target_col)).contains(\"united states\") | \n",
    "        lower(col(target_col)).contains(\" usa\") |\n",
    "        lower(col(target_col)).endswith(\"usa\")\n",
    "    )\n",
    "    \n",
    "    count = df_usa_booking.count()\n",
    "    print(f\"Filtered Row Count: {count}\")\n",
    "\n",
    "    if count > 0:\n",
    "        # Paths\n",
    "        temp_folder = \"Lodging_data/booking_usa_temp.parquet\"\n",
    "        final_path  = \"Lodging_data/booking_usa_FINAL.parquet\"\n",
    "\n",
    "        # 1. Save to temp folder\n",
    "        df_usa_booking.coalesce(1).write.mode(\"overwrite\").parquet(temp_folder)\n",
    "        \n",
    "        # 2. Rename/Move the single file to the final location\n",
    "        files = dbutils.fs.ls(temp_folder)\n",
    "        part_file = [f.name for f in files if f.name.startswith(\"part-\")][0]\n",
    "        dbutils.fs.cp(f\"{temp_folder}/{part_file}\", final_path)\n",
    "        \n",
    "        # 3. Cleanup temp folder (Optional, keeps things clean)\n",
    "        dbutils.fs.rm(temp_folder, recurse=True)\n",
    "\n",
    "        print(f\"\\nSUCCESS! File saved at:\\n{final_path}\")\n",
    "        \n",
    "        # Verify\n",
    "        print(\"\\nSample Data:\")\n",
    "        df_usa_booking.select(target_col).show(5, truncate=False)\n",
    "        \n",
    "    else:\n",
    "        print(\"Rows is 0. Check if the column selected actually contains 'United States'.\")\n",
    "else:\n",
    "    print(\"ERROR: Could not automatically find an 'address' or 'country' column.\")\n",
    "    print(\"Please look at the Schema output above and replace 'target_col' manually in the code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d43aae90-ce23-4d06-bf52-fede1feefa6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "USA Lodging data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f95e9949-ae96-473d-b145-fef9f758b99a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "path = \"Lodging_data/booking_usa_FINAL.parquet\""
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3f35be2-59ab-4e97-bd51-d25a22b59f01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Loading Airbnb Data ---\n=== Airbnb Schema ===\nroot\n |-- name: string (nullable = true)\n |-- price: string (nullable = true)\n |-- image: string (nullable = true)\n |-- description: string (nullable = true)\n |-- category: string (nullable = true)\n |-- availability: string (nullable = true)\n |-- discount: string (nullable = true)\n |-- reviews: string (nullable = true)\n |-- ratings: string (nullable = true)\n |-- seller_info: string (nullable = true)\n |-- breadcrumbs: string (nullable = true)\n |-- location: string (nullable = true)\n |-- lat: string (nullable = true)\n |-- long: string (nullable = true)\n |-- guests: string (nullable = true)\n |-- pets_allowed: string (nullable = true)\n |-- description_items: string (nullable = true)\n |-- category_rating: string (nullable = true)\n |-- house_rules: string (nullable = true)\n |-- details: string (nullable = true)\n |-- highlights: string (nullable = true)\n |-- arrangement_details: string (nullable = true)\n |-- amenities: string (nullable = true)\n |-- images: string (nullable = true)\n |-- available_dates: string (nullable = true)\n |-- url: string (nullable = true)\n |-- final_url: string (nullable = true)\n |-- listing_title: string (nullable = true)\n |-- property_id: string (nullable = true)\n |-- listing_name: string (nullable = true)\n |-- location_details: string (nullable = true)\n |-- description_by_sections: string (nullable = true)\n |-- description_html: string (nullable = true)\n |-- location_details_html: string (nullable = true)\n |-- is_supperhost: string (nullable = true)\n |-- host_number_of_reviews: string (nullable = true)\n |-- host_rating: string (nullable = true)\n |-- hosts_year: string (nullable = true)\n |-- host_response_rate: string (nullable = true)\n |-- is_guest_favorite: string (nullable = true)\n |-- travel_details: string (nullable = true)\n |-- pricing_details: string (nullable = true)\n |-- total_price: string (nullable = true)\n |-- currency: string (nullable = true)\n |-- cancellation_policy: string (nullable = true)\n |-- property_number_of_reviews: string (nullable = true)\n |-- country: string (nullable = true)\n |-- postcode_map_url: string (nullable = true)\n |-- host_image: string (nullable = true)\n |-- host_details: string (nullable = true)\n\n\nDetected Filtering Column: 'country'\nFiltering for 'United States' in column: country...\nFiltered Row Count: 0\n‚ö†Ô∏è Warning: Filter returned 0 rows. Check the casing or column content.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower\n",
    "import os\n",
    "\n",
    "# --- 1. SETUP CONFIGURATION ---\n",
    "storage_account = \"\"\n",
    "# Airbnb SAS Token (From your previous context)\n",
    "airbnb_sas = \"\"\n",
    "\n",
    "def set_airbnb_token():\n",
    "    spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"SAS\")\n",
    "    spark.conf.set(f\"fs.azure.sas.token.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "    spark.conf.set(f\"fs.azure.sas.fixed.token.{storage_account}.dfs.core.windows.net\", airbnb_sas)\n",
    "\n",
    "# Apply Token\n",
    "set_airbnb_token()\n",
    "\n",
    "# --- 2. LOAD DATA ---\n",
    "print(\"--- Loading Airbnb Data ---\")\n",
    "airbnb_path = f\"abfss://airbnb@{storage_account}.dfs.core.windows.net/airbnb_1_12_parquet\"\n",
    "df_airbnb = spark.read.parquet(airbnb_path)\n",
    "\n",
    "print(\"=== Airbnb Schema ===\")\n",
    "df_airbnb.printSchema()\n",
    "\n",
    "# --- 3. IDENTIFY LOCATION COLUMN ---\n",
    "# Auto-detect the best column to filter by\n",
    "columns = [c.lower() for c in df_airbnb.columns]\n",
    "target_col = None\n",
    "\n",
    "# Priority list for Airbnb datasets\n",
    "if \"country\" in columns:\n",
    "    target_col = \"country\"\n",
    "elif \"smart_location\" in columns: # Common in Airbnb scrapes\n",
    "    target_col = \"smart_location\"\n",
    "elif \"location\" in columns:\n",
    "    target_col = \"location\"\n",
    "elif \"address\" in columns:\n",
    "    target_col = \"address\"\n",
    "\n",
    "print(f\"\\nDetected Filtering Column: '{target_col}'\")\n",
    "\n",
    "# --- 4. FILTER & SAVE ---\n",
    "if target_col:\n",
    "    print(f\"Filtering for 'United States' in column: {target_col}...\")\n",
    "    \n",
    "    # Filter for United States / USA / US\n",
    "    df_usa_airbnb = df_airbnb.filter(\n",
    "        lower(col(target_col)).contains(\"united states\") | \n",
    "        lower(col(target_col)).contains(\" usa\") |\n",
    "        (lower(col(target_col)) == \"us\")\n",
    "    )\n",
    "    \n",
    "    count = df_usa_airbnb.count()\n",
    "    print(f\"Filtered Row Count: {count}\")\n",
    "\n",
    "    if count > 0:\n",
    "        # Define Paths\n",
    "        base_folder = \"Lodging_data\"\n",
    "        temp_folder = f\"{base_folder}/airbnb_usa_temp.parquet\"\n",
    "        final_path  = f\"{base_folder}/airbnb_usa.parquet\"\n",
    "\n",
    "        # 1. Save to temp folder (Single File)\n",
    "        print(\"Saving to temp location...\")\n",
    "        df_usa_airbnb.coalesce(1).write.mode(\"overwrite\").parquet(temp_folder)\n",
    "        \n",
    "        # 2. Rename/Move to final location\n",
    "        print(\"Renaming to final .parquet file...\")\n",
    "        files = dbutils.fs.ls(temp_folder)\n",
    "        # Find the part file (it starts with \"part-\")\n",
    "        part_file = [f.name for f in files if f.name.startswith(\"part-\")][0]\n",
    "        dbutils.fs.cp(f\"{temp_folder}/{part_file}\", final_path)\n",
    "        \n",
    "        # 3. Cleanup\n",
    "        dbutils.fs.rm(temp_folder, recurse=True)\n",
    "\n",
    "        print(f\"\\n‚úÖ SUCCESS! Airbnb USA data saved at:\\n{final_path}\")\n",
    "        \n",
    "        # Verify\n",
    "        print(\"\\nSample Data:\")\n",
    "        df_usa_airbnb.select(target_col).show(5, truncate=False)\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Warning: Filter returned 0 rows. Check the casing or column content.\")\n",
    "else:\n",
    "    print(\"‚ùå ERROR: Could not automatically find a location column.\")\n",
    "    print(\"Please check the schema printed above and update 'target_col' manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f95d2ab-7fa2-4c91-9939-3c96af0b8ee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Loading airbnb and booking.com data (made my own dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "773c18c5-d031-4427-a373-72e30ad34965",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Preprocessing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "580903aa-9aa0-4151-ab87-1e9b55c60f63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dynamic Price Cutoff (95%): $1065.00\nCleaning text fields...\nReady for Training: 1,365,151 rows\n\n--- New Room Type Distribution ---\n+---------------+-------+\n|      room_type|  count|\n+---------------+-------+\n|   Private Room|1062632|\n|Entire Home/Apt| 272085|\n|          Hotel|  30434|\n+---------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# --- BLOCK 1: ADVANCED PREPROCESSING ---\n",
    "from pyspark.sql.functions import col, lit, split, element_at, regexp_extract, trim, size, when, lower, regexp_replace, length\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Imputer\n",
    "\n",
    "# 2. Airbnb Transformation (With Smart Feature Extraction)\n",
    "df_airbnb_clean = df_airbnb.select(\n",
    "    lit(\"Airbnb\").alias(\"source\"),\n",
    "    # Clean Price\n",
    "    regexp_replace(col(\"price\"), \"[\\$,]\", \"\").cast(\"double\").alias(\"price\"),\n",
    "    \n",
    "    # Location Extraction\n",
    "    trim(element_at(split(col(\"location\"), \",\"), -2)).alias(\"state\"),\n",
    "    trim(element_at(split(col(\"location\"), \",\"), -3)).alias(\"city\"), # <--- NEW: Added City\n",
    "    \n",
    "    # Smart Room Type Logic (The Fix for \"Stays\")\n",
    "    when(lower(col(\"name\")).contains(\"shared room\"), \"Shared Room\")\n",
    "    .when(lower(col(\"name\")).contains(\"private room\"), \"Private Room\")\n",
    "    .when(lower(col(\"name\")).contains(\"hotel\"), \"Hotel\")\n",
    "    # \"Entire\", \"House\", \"Apt\", \"Villa\" all imply the whole place\n",
    "    .when(lower(col(\"name\")).rlike(\"entire|house|apt|apartment|villa|condo\"), \"Entire Home/Apt\")\n",
    "    .otherwise(\"Private Room\") # Safe fallback\n",
    "    .alias(\"room_type\"),\n",
    "    \n",
    "    # Other Features\n",
    "    regexp_replace(col(\"guests\"), \"[^0-9]\", \"\").cast(\"int\").alias(\"guests\"),\n",
    "    regexp_extract(col(\"ratings\"), \"([0-9]+\\.[0-9]+)\", 1).cast(\"double\").alias(\"rating\"),\n",
    "    regexp_extract(col(\"reviews\"), \"([0-9]+)\", 1).cast(\"int\").alias(\"review_count\"),\n",
    "    size(split(col(\"amenities\"), \",\")).alias(\"amenities_count\"),\n",
    "    regexp_extract(col(\"host_rating\"), \"([0-9]+\\.[0-9]+)\", 1).cast(\"double\").alias(\"host_score\"),\n",
    "    length(col(\"description\")).alias(\"desc_length\")\n",
    ")\n",
    "\n",
    "# 3. Booking Transformation (Aligning Columns)\n",
    "df_booking_clean = df_booking.select(\n",
    "    lit(\"Booking\").alias(\"source\"),\n",
    "    lit(None).cast(\"double\").alias(\"price\"),\n",
    "    trim(element_at(split(col(\"location\"), \",\"), -2)).alias(\"state\"),\n",
    "    trim(element_at(split(col(\"location\"), \",\"), -3)).alias(\"city\"), # <--- NEW\n",
    "    # Booking usually has good room types, but we map them to match Airbnb if needed\n",
    "    col(\"availability\")[0][\"room_type\"].alias(\"room_type\"),\n",
    "    col(\"availability\")[0][\"max_number_of_guests\"].cast(\"int\").alias(\"guests\"),\n",
    "    col(\"review_score\").alias(\"rating\"),\n",
    "    col(\"number_of_reviews\").cast(\"int\").alias(\"review_count\"),\n",
    "    size(col(\"most_popular_facilities\")).alias(\"amenities_count\"),\n",
    "    (col(\"manager_score\") / 2).alias(\"host_score\"), \n",
    "    length(col(\"description\")).alias(\"desc_length\")\n",
    ")\n",
    "\n",
    "# 4. Merge\n",
    "df_master = df_airbnb_clean.unionByName(df_booking_clean)\n",
    "\n",
    "# --- FILTERING & CLEANING ---\n",
    "\n",
    "# A. Filter for Training (Must have Price)\n",
    "df_with_price = df_master.filter(col(\"price\").isNotNull())\n",
    "\n",
    "# B. Dynamic Outlier Removal (95th Percentile)\n",
    "high_limit = df_with_price.stat.approxQuantile(\"price\", [0.95], 0.01)[0]\n",
    "print(f\"Dynamic Price Cutoff (95%): ${high_limit:.2f}\")\n",
    "\n",
    "df_train = df_with_price.filter(\n",
    "    (col(\"price\") > 15) &  # Increased floor slightly to avoid errors\n",
    "    (col(\"price\") <= high_limit) & \n",
    "    (col(\"guests\") > 0)\n",
    ")\n",
    "\n",
    "# C. Clean Text Columns (Remove \"United States\" as state, empty strings)\n",
    "print(\"Cleaning text fields...\")\n",
    "df_train = df_train.filter(\n",
    "    (col(\"state\").isNotNull()) & (length(trim(col(\"state\"))) > 0) & (col(\"state\") != \"United States\") &\n",
    "    (col(\"room_type\").isNotNull()) & (length(trim(col(\"room_type\"))) > 0)\n",
    ")\n",
    "\n",
    "# D. Impute Missing Values\n",
    "defaults = {\n",
    "    \"rating\": 4.5, \"review_count\": 0, \"amenities_count\": 5, \n",
    "    \"host_score\": 4.5, \"desc_length\": 100, \"city\": \"Unknown\"\n",
    "}\n",
    "df_train = df_train.na.fill(defaults)\n",
    "\n",
    "print(f\"Ready for Training: {df_train.count():,} rows\")\n",
    "\n",
    "# Check the new Room Types!\n",
    "print(\"\\n--- New Room Type Distribution ---\")\n",
    "df_train.groupBy(\"room_type\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a9f2871-fff3-4594-bbb1-22581d84df00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4108a4f8-9e20-4894-9de2-2af720eb9cb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29d10693-3d4a-42fe-b3c2-276321491cfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- 1. Processing Data in Spark ---\n   -> Price Ceiling (95%): $1233.19\n   -> Cleaning text and imputing defaults...\n‚úÖ Ready for Training: 1,371,680 rows\n\n--- 2. Training XGBoost Model ---\n   -> Dataset large, taking 500k sample for efficient training...\n   -> Training on 400472 rows with max_depth=5, n_estimators=50...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17df42a6f2bb496d8e6e1b7db30ec668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üèÉ View run bemused-gnat-629 at: https://adb-983293358114278.18.azuredatabricks.net/ml/experiments/1072358835225203/runs/42208d559fe942e59702918f9d32d934\nüß™ View experiment at: https://adb-983293358114278.18.azuredatabricks.net/ml/experiments/1072358835225203\n‚úÖ Model Results: RMSE=$143.12 | R2=0.327\n\n--- 3. Saving Brain for Agent ---\nüéâ SUCCESS! Model saved to: /dbfs/Workspace/Users/gil.caplan@campus.technion.ac.il/lodging_cost_predictor_v1.pkl\nYou can now download this file to your laptop.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col, lit, split, element_at, regexp_extract, trim, size, when, lower, regexp_replace, length\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- PART 1: PREPROCESSING (Your Exact Logic) ---\n",
    "print(\"--- 1. Processing Data in Spark ---\")\n",
    "\n",
    "# 1. Airbnb Transformation\n",
    "df_airbnb_clean = df_airbnb.select(\n",
    "    lit(\"Airbnb\").alias(\"source\"),\n",
    "    # Fix: Added 'r' to regex strings to avoid syntax warnings\n",
    "    regexp_replace(col(\"price\"), r\"[\\$,]\", \"\").cast(\"double\").alias(\"price\"),\n",
    "    trim(element_at(split(col(\"location\"), \",\"), -2)).alias(\"state\"),\n",
    "    trim(element_at(split(col(\"location\"), \",\"), -3)).alias(\"city\"),\n",
    "    \n",
    "    # Smart Room Type Logic\n",
    "    when(lower(col(\"name\")).contains(\"shared room\"), \"Shared Room\")\n",
    "    .when(lower(col(\"name\")).contains(\"private room\"), \"Private Room\")\n",
    "    .when(lower(col(\"name\")).contains(\"hotel\"), \"Hotel\")\n",
    "    .when(lower(col(\"name\")).rlike(\"entire|house|apt|apartment|villa|condo\"), \"Entire Home/Apt\")\n",
    "    .otherwise(\"Private Room\").alias(\"room_type\"),\n",
    "    \n",
    "    # Features\n",
    "    regexp_replace(col(\"guests\"), \"[^0-9]\", \"\").cast(\"int\").alias(\"guests\"),\n",
    "    regexp_extract(col(\"ratings\"), r\"([0-9]+\\.[0-9]+)\", 1).cast(\"double\").alias(\"rating\"),\n",
    "    regexp_extract(col(\"reviews\"), r\"([0-9]+)\", 1).cast(\"int\").alias(\"review_count\"),\n",
    "    size(split(col(\"amenities\"), \",\")).alias(\"amenities_count\"),\n",
    "    regexp_extract(col(\"host_rating\"), r\"([0-9]+\\.[0-9]+)\", 1).cast(\"double\").alias(\"host_score\"),\n",
    "    length(col(\"description\")).alias(\"desc_length\")\n",
    ")\n",
    "\n",
    "# 2. Booking Transformation\n",
    "df_booking_clean = df_booking.select(\n",
    "    lit(\"Booking\").alias(\"source\"),\n",
    "    lit(None).cast(\"double\").alias(\"price\"),\n",
    "    trim(element_at(split(col(\"location\"), \",\"), -2)).alias(\"state\"),\n",
    "    trim(element_at(split(col(\"location\"), \",\"), -3)).alias(\"city\"),\n",
    "    col(\"availability\")[0][\"room_type\"].alias(\"room_type\"),\n",
    "    col(\"availability\")[0][\"max_number_of_guests\"].cast(\"int\").alias(\"guests\"),\n",
    "    col(\"review_score\").alias(\"rating\"),\n",
    "    col(\"number_of_reviews\").cast(\"int\").alias(\"review_count\"),\n",
    "    size(col(\"most_popular_facilities\")).alias(\"amenities_count\"),\n",
    "    (col(\"manager_score\") / 2).alias(\"host_score\"), \n",
    "    length(col(\"description\")).alias(\"desc_length\")\n",
    ")\n",
    "\n",
    "# 3. Merge & Filter\n",
    "df_master = df_airbnb_clean.unionByName(df_booking_clean)\n",
    "df_with_price = df_master.filter(col(\"price\").isNotNull())\n",
    "\n",
    "# 4. Outlier Removal (95th Percentile)\n",
    "high_limit = df_with_price.stat.approxQuantile(\"price\", [0.95], 0.01)[0]\n",
    "print(f\"   -> Price Ceiling (95%): ${high_limit:.2f}\")\n",
    "\n",
    "df_train = df_with_price.filter(\n",
    "    (col(\"price\") > 15) & \n",
    "    (col(\"price\") <= high_limit) & \n",
    "    (col(\"guests\") > 0)\n",
    ")\n",
    "\n",
    "# 5. Clean Text & Impute\n",
    "print(\"   -> Cleaning text and imputing defaults...\")\n",
    "df_train = df_train.filter(\n",
    "    (col(\"state\").isNotNull()) & (length(trim(col(\"state\"))) > 0) & (col(\"state\") != \"United States\") &\n",
    "    (col(\"room_type\").isNotNull()) & (length(trim(col(\"room_type\"))) > 0)\n",
    ")\n",
    "\n",
    "defaults = {\"rating\": 4.5, \"review_count\": 0, \"amenities_count\": 5, \"host_score\": 4.5, \"desc_length\": 100, \"city\": \"Unknown\"}\n",
    "df_train = df_train.na.fill(defaults)\n",
    "\n",
    "row_count = df_train.count()\n",
    "print(f\"‚úÖ Ready for Training: {row_count:,} rows\")\n",
    "\n",
    "\n",
    "# --- PART 2: TRAINING (Pandas + XGBoost) ---\n",
    "print(\"\\n--- 2. Training XGBoost Model ---\")\n",
    "\n",
    "# 1. Convert to Pandas\n",
    "# If dataset > 500k rows, sample it to prevent OOM errors on the driver\n",
    "if row_count > 500000:\n",
    "    print(\"   -> Dataset large, taking 500k sample for efficient training...\")\n",
    "    pdf = df_train.sample(False, 500000.0/row_count, seed=42).toPandas()\n",
    "else:\n",
    "    pdf = df_train.toPandas()\n",
    "\n",
    "# 2. Feature Engineering (For the Laptop Agent)\n",
    "# Keep Top 50 States, group others\n",
    "top_states = pdf['state'].value_counts().nlargest(50).index.tolist()\n",
    "pdf['clean_state'] = pdf['state'].apply(lambda x: x if x in top_states else 'Other')\n",
    "\n",
    "# Create Input Matrix (One-Hot Encoding)\n",
    "X = pd.get_dummies(pdf[[\n",
    "    'clean_state', 'room_type', 'guests', 'rating', \n",
    "    'review_count', 'amenities_count', 'host_score', 'desc_length'\n",
    "]], drop_first=True)\n",
    "y = pdf['price']\n",
    "\n",
    "# 3. Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Train XGBoost \n",
    "# Using parameters: Max Depth = 5, Iterations (Estimators) = 50\n",
    "print(f\"   -> Training on {len(X_train)} rows with max_depth=5, n_estimators=50...\")\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    max_depth=5,        # From your hyperparameter search\n",
    "    n_estimators=50,    # Matches \"maxIter=50\"\n",
    "    learning_rate=0.1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate\n",
    "rmse = float(np.sqrt(((y_test - model.predict(X_test)) ** 2).mean()))\n",
    "r2 = model.score(X_test, y_test)\n",
    "print(f\"‚úÖ Model Results: RMSE=${rmse:.2f} | R2={r2:.3f}\")\n",
    "\n",
    "# --- PART 3: SAVE ARTIFACTS ---\n",
    "print(\"\\n--- 3. Saving Brain for Agent ---\")\n",
    "\n",
    "artifacts = {\n",
    "    \"lodging_model\": model,\n",
    "    \"model_columns\": X_train.columns.tolist(), # Vital for alignment\n",
    "    \"stats\": {\"rmse\": rmse, \"avg_price\": float(y.mean())}\n",
    "}\n",
    "\n",
    "save_path = \"/dbfs/Workspace/Users/gil.caplan@campus.technion.ac.il/lodging_cost_predictor_v1.pkl\"\n",
    "joblib.dump(artifacts, save_path)\n",
    "\n",
    "print(f\"üéâ SUCCESS! Model saved to: {save_path}\")\n",
    "print(\"You can now download this file to your laptop.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e3f7206-709d-480b-a8e0-c3afb1e1226f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30211f89-1e6e-4efc-9b66-0efe4deeb8e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Final Model (Depth=5, Iter=50)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ac165f09804d7fb0cfb6696f8ac618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe60c943a484905abe032a5eda8d6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üèÉ View run tasteful-sloth-963 at: https://adb-983293358114278.18.azuredatabricks.net/ml/experiments/1072358835225203/runs/f05c2b9bad554d75a4fc33c3a867c3d8\nüß™ View experiment at: https://adb-983293358114278.18.azuredatabricks.net/ml/experiments/1072358835225203\nTraining Complete!\n\n--- FINAL MODEL SCORECARD ---\nError (RMSE): $130.41\nAccuracy (R2): 0.357 (Explains 35.7% of variance)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col, trim, length\n",
    "\n",
    "# 1. Clean & Split Data\n",
    "# Ensure we don't have empty strings that crash the model\n",
    "df_train_clean = df_train.filter(\n",
    "    (col(\"state\").isNotNull()) & (length(trim(col(\"state\"))) > 0) &\n",
    "    (col(\"room_type\").isNotNull()) & (length(trim(col(\"room_type\"))) > 0)\n",
    ")\n",
    "\n",
    "train_data, test_data = df_train_clean.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 2. Define The Pipeline Stages\n",
    "# These turn text (State, Room Type) into numbers the model understands\n",
    "state_indexer = StringIndexer(inputCol=\"state\", outputCol=\"state_index\", handleInvalid=\"skip\")\n",
    "room_indexer  = StringIndexer(inputCol=\"room_type\", outputCol=\"room_index\", handleInvalid=\"keep\")\n",
    "\n",
    "state_encoder = OneHotEncoder(inputCols=[\"state_index\"], outputCols=[\"state_vec\"])\n",
    "room_encoder  = OneHotEncoder(inputCols=[\"room_index\"], outputCols=[\"room_vec\"])\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"guests\", \"state_vec\", \"room_vec\", \"rating\", \"review_count\", \"amenities_count\", \"host_score\", \"desc_length\"], \n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# 3. The Optimized Model (Hardcoded with Winners)\n",
    "# We use maxDepth=5 and maxIter=50 directly\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"price\", maxDepth=5, maxIter=50, seed=42)\n",
    "\n",
    "pipeline = Pipeline(stages=[state_indexer, room_indexer, state_encoder, room_encoder, assembler, gbt])\n",
    "\n",
    "# 4. Train\n",
    "print(\"Training Final Model (Depth=5, Iter=50)...\")\n",
    "final_model = pipeline.fit(train_data)\n",
    "print(\"Training Complete!\")\n",
    "\n",
    "# 5. Validate\n",
    "predictions = final_model.transform(test_data)\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(f\"\\n--- FINAL MODEL SCORECARD ---\")\n",
    "print(f\"Error (RMSE): ${rmse:.2f}\")\n",
    "print(f\"Accuracy (R2): {r2:.3f} (Explains {r2*100:.1f}% of variance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad0edebe-fd20-4a59-8c63-038d0fdadf87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Calculate Lodging costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "722a5246-efd8-4b1d-8f2d-4f291c204f79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Estimate for New York (3 nights) ---\nFeatures: 2 Guests, Entire home/apt, 4.8 Stars\nRate:     $124.79 / night\nTOTAL:    $374.36\n\n--- Estimate for Texas (5 nights) ---\nFeatures: 4 Guests, Entire home/apt, 4.8 Stars\nRate:     $117.52 / night\nTOTAL:    $587.61\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "587.6091215781203"
      ]
     },
     "execution_count": 7,
     "metadata": {}
    }
   ],
   "source": [
    "# --- BLOCK 4: CALCULATOR ---\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "def predict_trip_cost(state, travelers, nights, room_type=\"Entire home/apt\", rating=4.8, reviews=50, amenities=15, host_score=4.9, desc_len=500):\n",
    "    \n",
    "    # Schema must match Training Data exactly\n",
    "    schema = StructType([\n",
    "        StructField(\"state\", StringType(), True),\n",
    "        StructField(\"guests\", IntegerType(), True),\n",
    "        StructField(\"room_type\", StringType(), True),\n",
    "        StructField(\"rating\", DoubleType(), True),\n",
    "        StructField(\"review_count\", IntegerType(), True),\n",
    "        StructField(\"amenities_count\", IntegerType(), True),\n",
    "        StructField(\"host_score\", DoubleType(), True),\n",
    "        StructField(\"desc_length\", IntegerType(), True)\n",
    "    ])\n",
    "    \n",
    "    data = [(state, travelers, room_type, rating, reviews, amenities, host_score, desc_len)]\n",
    "    input_df = spark.createDataFrame(data, schema)\n",
    "    \n",
    "    try:\n",
    "        # Use the 'best_model' from Cross Validation\n",
    "        result = final_model.transform(input_df)\n",
    "        price_per_night = result.collect()[0][\"prediction\"]\n",
    "        total = price_per_night * nights\n",
    "        \n",
    "        print(f\"--- Estimate for {state} ({nights} nights) ---\")\n",
    "        print(f\"Features: {travelers} Guests, {room_type}, {rating} Stars\")\n",
    "        print(f\"Rate:     ${price_per_night:.2f} / night\")\n",
    "        print(f\"TOTAL:    ${total:.2f}\\n\")\n",
    "        return total\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}. State '{state}' might not be in the training data.\")\n",
    "\n",
    "# --- TRY IT OUT ---\n",
    "predict_trip_cost(\"New York\", travelers=2, nights=3)\n",
    "predict_trip_cost(\"Texas\", travelers=4, nights=5, room_type=\"Entire home/apt\", amenities=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55ada8ca-1feb-4fb2-bfbd-637454d50b8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====== MODEL LOGIC CHECKS ======\n\n1. LOCATION SENSITIVITY (2 Guests, Entire Home)\n--- Estimate for New York (1 nights) ---\nFeatures: 2 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $124.79 / night\nTOTAL:    $124.79\n\n--- Estimate for Kansas (1 nights) ---\nFeatures: 2 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $81.14 / night\nTOTAL:    $81.14\n\n   -> Result: NY is 53.8% more expensive than KS. ‚úÖ PASS\n\n2. TYPE SENSITIVITY (Texas, 2 Guests)\n--- Estimate for Texas (1 nights) ---\nFeatures: 2 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $81.14 / night\nTOTAL:    $81.14\n\n--- Estimate for Texas (1 nights) ---\nFeatures: 2 Guests, Private Room, 4.8 Stars\nRate:     $71.42 / night\nTOTAL:    $71.42\n\n   -> Result: Entire Home is 13.6% more expensive than Room. ‚úÖ PASS\n\n3. CAPACITY SENSITIVITY (Florida, Entire Home)\n--- Estimate for Florida (1 nights) ---\nFeatures: 1 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $104.13 / night\nTOTAL:    $104.13\n\n--- Estimate for Florida (1 nights) ---\nFeatures: 6 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $177.21 / night\nTOTAL:    $177.21\n\n   -> Result: 6 Guests cost 70.2% more than 1 Guest. ‚úÖ PASS\n\n4. LUXURY SENSITIVITY (California, Entire Home)\n--- Estimate for California (1 nights) ---\nFeatures: 2 Guests, Entire home/apt, 5.0 Stars\nRate:     $167.14 / night\nTOTAL:    $167.14\n\n--- Estimate for California (1 nights) ---\nFeatures: 2 Guests, Entire home/apt, 3.5 Stars\nRate:     $177.30 / night\nTOTAL:    $177.30\n\n   -> Result: Luxury listing is -5.7% more expensive. ‚ùå FAIL\n"
     ]
    }
   ],
   "source": [
    "def run_sanity_check():\n",
    "    print(\"====== MODEL LOGIC CHECKS ======\")\n",
    "    \n",
    "    # CHECK 1: The \"New York vs. Kansas\" Test (Location)\n",
    "    # Logic: Expensive state should cost more than cheaper state for identical listing\n",
    "    print(\"\\n1. LOCATION SENSITIVITY (2 Guests, Entire Home)\")\n",
    "    p_ny = predict_trip_cost(\"New York\", 2, 1, room_type=\"Entire Home/Apt\")\n",
    "    p_ks = predict_trip_cost(\"Kansas\", 2, 1, room_type=\"Entire Home/Apt\")\n",
    "    \n",
    "    diff = ((p_ny - p_ks) / p_ks) * 100\n",
    "    print(f\"   -> Result: NY is {diff:.1f}% more expensive than KS. \" + (\"‚úÖ PASS\" if p_ny > p_ks else \"‚ùå FAIL\"))\n",
    "\n",
    "    # CHECK 2: The \"Mansion vs. Room\" Test (Room Type)\n",
    "    # Logic: Entire home must cost more than a private room\n",
    "    print(\"\\n2. TYPE SENSITIVITY (Texas, 2 Guests)\")\n",
    "    p_home = predict_trip_cost(\"Texas\", 2, 1, room_type=\"Entire Home/Apt\")\n",
    "    p_room = predict_trip_cost(\"Texas\", 2, 1, room_type=\"Private Room\")\n",
    "    \n",
    "    diff = ((p_home - p_room) / p_room) * 100\n",
    "    print(f\"   -> Result: Entire Home is {diff:.1f}% more expensive than Room. \" + (\"‚úÖ PASS\" if p_home > p_room else \"‚ùå FAIL\"))\n",
    "\n",
    "    # CHECK 3: The \"Crowd\" Test (Guest Count)\n",
    "    # Logic: 6 guests should cost more than 1 guest (usually implies bigger house)\n",
    "    print(\"\\n3. CAPACITY SENSITIVITY (Florida, Entire Home)\")\n",
    "    p_1g = predict_trip_cost(\"Florida\", 1, 1, room_type=\"Entire Home/Apt\")\n",
    "    p_6g = predict_trip_cost(\"Florida\", 6, 1, room_type=\"Entire Home/Apt\")\n",
    "    \n",
    "    diff = ((p_6g - p_1g) / p_1g) * 100\n",
    "    print(f\"   -> Result: 6 Guests cost {diff:.1f}% more than 1 Guest. \" + (\"‚úÖ PASS\" if p_6g > p_1g else \"‚ùå FAIL\"))\n",
    "\n",
    "    # CHECK 4: The \"Luxury\" Test (Quality)\n",
    "    # Logic: High rating (5.0) + Many Amenities (30) vs Low rating (3.0) + Few Amenities (5)\n",
    "    print(\"\\n4. LUXURY SENSITIVITY (California, Entire Home)\")\n",
    "    p_lux = predict_trip_cost(\"California\", 2, 1, rating=5.0, amenities=30, reviews=100)\n",
    "    p_basic = predict_trip_cost(\"California\", 2, 1, rating=3.5, amenities=5, reviews=5)\n",
    "    \n",
    "    diff = ((p_lux - p_basic) / p_basic) * 100\n",
    "    print(f\"   -> Result: Luxury listing is {diff:.1f}% more expensive. \" + (\"‚úÖ PASS\" if p_lux > p_basic else \"‚ùå FAIL\"))\n",
    "\n",
    "# Run the checks\n",
    "run_sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff41c7ff-db3f-4c6a-89f5-3d4d548920e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "STATE           | TYPE            | EST. PRICE\n---------------------------------------------\n--- Estimate for California (1 nights) ---\nFeatures: 2 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $163.35 / night\nTOTAL:    $163.35\n\n--- Estimate for Washington (1 nights) ---\nFeatures: 2 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $100.40 / night\nTOTAL:    $100.40\n\n--- Estimate for Texas (1 nights) ---\nFeatures: 2 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $81.14 / night\nTOTAL:    $81.14\n\n--- Estimate for Ohio (1 nights) ---\nFeatures: 2 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $81.14 / night\nTOTAL:    $81.14\n\n--- Estimate for Florida (1 nights) ---\nFeatures: 2 Guests, Entire Home/Apt, 4.8 Stars\nRate:     $104.13 / night\nTOTAL:    $104.13\n\n"
     ]
    }
   ],
   "source": [
    "# List of diverse scenarios to test the model's \"Economic IQ\"\n",
    "test_cases = [\n",
    "    # 1. The Expensive West Coast\n",
    "    {\"state\": \"California\", \"city\": \"Los Angeles\", \"guests\": 2, \"nights\": 1, \"type\": \"Entire Home/Apt\"},\n",
    "    \n",
    "    # 2. The Tech Hub / Pacific Northwest\n",
    "    {\"state\": \"Washington\", \"city\": \"Seattle\", \"guests\": 2, \"nights\": 1, \"type\": \"Entire Home/Apt\"},\n",
    "    \n",
    "    # 3. The South (Should be cheaper than CA/WA)\n",
    "    {\"state\": \"Texas\", \"city\": \"Austin\", \"guests\": 2, \"nights\": 1, \"type\": \"Entire Home/Apt\"},\n",
    "    \n",
    "    # 4. The Midwest (Usually the most affordable)\n",
    "    {\"state\": \"Ohio\", \"city\": \"Columbus\", \"guests\": 2, \"nights\": 1, \"type\": \"Entire Home/Apt\"},\n",
    "    \n",
    "    # 5. Vacation State (High variance, usually high)\n",
    "    {\"state\": \"Florida\", \"city\": \"Miami\", \"guests\": 2, \"nights\": 1, \"type\": \"Entire Home/Apt\"}\n",
    "]\n",
    "\n",
    "print(f\"{'STATE':<15} | {'TYPE':<15} | {'EST. PRICE':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for test in test_cases:\n",
    "    # We call the model for each case\n",
    "    # Note: We pass standard rating/amenities to keep it a fair comparison\n",
    "    try:\n",
    "        cost = predict_trip_cost(\n",
    "            state=test[\"state\"], \n",
    "            travelers=test[\"guests\"], \n",
    "            nights=test[\"nights\"], \n",
    "            room_type=test[\"type\"],\n",
    "            rating=4.8,\n",
    "            amenities=15\n",
    "        )\n",
    "        # We perform the print inside the function, but let's grab the return value to compare\n",
    "        # (The function prints detailed info, but we can verify relative order here)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4aaa860-6a62-42be-a934-a73ef8488533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNotADirectoryError\u001B[0m                        Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-7365365094603509>, line 43\u001B[0m\n",
       "\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Run for both\u001B[39;00m\n",
       "\u001B[1;32m     42\u001B[0m zip_and_move(airbnb_src, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mairbnb_usa_download\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m---> 43\u001B[0m zip_and_move(booking_src, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbooking_usa_download\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124müéâ Done. Go to your Workspace folder to download the .zip files.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m<command-7365365094603509>, line 32\u001B[0m, in \u001B[0;36mzip_and_move\u001B[0;34m(source_path, zip_name)\u001B[0m\n",
       "\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Create zip in local /tmp folder\u001B[39;00m\n",
       "\u001B[1;32m     31\u001B[0m base_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(temp_dir, zip_name)\n",
       "\u001B[0;32m---> 32\u001B[0m shutil\u001B[38;5;241m.\u001B[39mmake_archive(base_name, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzip\u001B[39m\u001B[38;5;124m'\u001B[39m, source_path)\n",
       "\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Move the finished zip to the Workspace\u001B[39;00m\n",
       "\u001B[1;32m     35\u001B[0m zip_file \u001B[38;5;241m=\u001B[39m base_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.zip\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.11/shutil.py:1150\u001B[0m, in \u001B[0;36mmake_archive\u001B[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001B[0m\n",
       "\u001B[1;32m   1148\u001B[0m stmd \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstat(root_dir)\u001B[38;5;241m.\u001B[39mst_mode\n",
       "\u001B[1;32m   1149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stat\u001B[38;5;241m.\u001B[39mS_ISDIR(stmd):\n",
       "\u001B[0;32m-> 1150\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotADirectoryError\u001B[39;00m(errno\u001B[38;5;241m.\u001B[39mENOTDIR, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNot a directory\u001B[39m\u001B[38;5;124m'\u001B[39m, root_dir)\n",
       "\u001B[1;32m   1152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m supports_root_dir:\n",
       "\u001B[1;32m   1153\u001B[0m     \u001B[38;5;66;03m# Support path-like base_name here for backwards-compatibility.\u001B[39;00m\n",
       "\u001B[1;32m   1154\u001B[0m     base_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(base_name)\n",
       "\n",
       "\u001B[0;31mNotADirectoryError\u001B[0m: [Errno 20] Not a directory: '/dbfs/Workspace/Users/gil.caplan@campus.technion.ac.il/Lodging_data/booking_usa_FINAL.parquet'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NotADirectoryError",
        "evalue": "[Errno 20] Not a directory: '/dbfs/Workspace/Users/gil.caplan@campus.technion.ac.il/Lodging_data/booking_usa_FINAL.parquet'"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNotADirectoryError\u001B[0m                        Traceback (most recent call last)",
        "File \u001B[0;32m<command-7365365094603509>, line 43\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Run for both\u001B[39;00m\n\u001B[1;32m     42\u001B[0m zip_and_move(airbnb_src, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mairbnb_usa_download\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 43\u001B[0m zip_and_move(booking_src, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbooking_usa_download\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124müéâ Done. Go to your Workspace folder to download the .zip files.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m<command-7365365094603509>, line 32\u001B[0m, in \u001B[0;36mzip_and_move\u001B[0;34m(source_path, zip_name)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Create zip in local /tmp folder\u001B[39;00m\n\u001B[1;32m     31\u001B[0m base_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(temp_dir, zip_name)\n\u001B[0;32m---> 32\u001B[0m shutil\u001B[38;5;241m.\u001B[39mmake_archive(base_name, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzip\u001B[39m\u001B[38;5;124m'\u001B[39m, source_path)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Move the finished zip to the Workspace\u001B[39;00m\n\u001B[1;32m     35\u001B[0m zip_file \u001B[38;5;241m=\u001B[39m base_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.zip\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
        "File \u001B[0;32m/usr/lib/python3.11/shutil.py:1150\u001B[0m, in \u001B[0;36mmake_archive\u001B[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001B[0m\n\u001B[1;32m   1148\u001B[0m stmd \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstat(root_dir)\u001B[38;5;241m.\u001B[39mst_mode\n\u001B[1;32m   1149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stat\u001B[38;5;241m.\u001B[39mS_ISDIR(stmd):\n\u001B[0;32m-> 1150\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotADirectoryError\u001B[39;00m(errno\u001B[38;5;241m.\u001B[39mENOTDIR, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNot a directory\u001B[39m\u001B[38;5;124m'\u001B[39m, root_dir)\n\u001B[1;32m   1152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m supports_root_dir:\n\u001B[1;32m   1153\u001B[0m     \u001B[38;5;66;03m# Support path-like base_name here for backwards-compatibility.\u001B[39;00m\n\u001B[1;32m   1154\u001B[0m     base_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(base_name)\n",
        "\u001B[0;31mNotADirectoryError\u001B[0m: [Errno 20] Not a directory: '/dbfs/Workspace/Users/gil.caplan@campus.technion.ac.il/Lodging_data/booking_usa_FINAL.parquet'"
       ],
       "type": "baseError"
      }
     }
    }
   ],
   "source": [
    "# Define a permanent path in your workspace\n",
    "model_path = \"/Workspace/Users/gil.caplan@campus.technion.ac.il/Lodging_data/airbnb_price_model_v1\"\n",
    "\n",
    "# Save the model (Overwrite if it exists)\n",
    "print(f\"Saving model to {model_path}...\")\n",
    "final_model.write().overwrite().save(model_path)\n",
    "print(\"SUCCESS: Model saved! You can now load this tomorrow without retraining.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9e2761e-f360-4cfd-95ab-706e8e1f58e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cfb6307-3b50-4439-a227-124def42010f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "America_lodgings",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
