{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "884fa43e-f7e1-4e12-af7a-8d2f05c89931",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "ROOT_PATH = 'ADD'\n",
    "FOLDERS = [\"Grocery_data\", \"New_York_data_food\", \"UberEats\", \"Yelp Data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf81065b-1285-4e42-b541-23abbe6a9d38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 1. FIXED STATE MAP (Keys use spaces)\n",
    "state_map = {\n",
    "    'alabama': 'AL', 'alaska': 'AK', 'arizona': 'AZ', 'arkansas': 'AR', 'california': 'CA',\n",
    "    'colorado': 'CO', 'connecticut': 'CT', 'delaware': 'DE', 'florida': 'FL', 'georgia': 'GA',\n",
    "    'hawaii': 'HI', 'idaho': 'ID', 'illinois': 'IL', 'indiana': 'IN', 'iowa': 'IA',\n",
    "    'kansas': 'KS', 'kentucky': 'KY', 'louisiana': 'LA', 'maine': 'ME', 'maryland': 'MD',\n",
    "    'massachusetts': 'MA', 'michigan': 'MI', 'minnesota': 'MN', 'mississippi': 'MS', 'missouri': 'MO',\n",
    "    'montana': 'MT', 'nebraska': 'NE', 'nevada': 'NV', 'new hampshire': 'NH', 'new jersey': 'NJ',\n",
    "    'new mexico': 'NM', 'new york': 'NY', 'north carolina': 'NC', 'north dakota': 'ND', 'ohio': 'OH',\n",
    "    'oklahoma': 'OK', 'oregon': 'OR', 'pennsylvania': 'PA', 'rhode island': 'RI', 'south carolina': 'SC',\n",
    "    'south dakota': 'SD', 'tennessee': 'TN', 'texas': 'TX', 'utah': 'UT', 'vermont': 'VT',\n",
    "    'virginia': 'VA', 'washington': 'WA', 'west virginia': 'WV', 'wisconsin': 'WI', 'wyoming': 'WY',\n",
    "    'district of columbia': 'DC'\n",
    "}\n",
    "def extract_state(state_input):\n",
    "    \"\"\"\n",
    "    Standardizes state input by mapping full names to 2-letter codes.\n",
    "    Handles various delimiters (commas, underscores, spaces) and case sensitivity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cleaning the input string\n",
    "    state_input = state_input.replace('_', ' ').replace(',', ' ').strip().title()\n",
    "\n",
    "    # Check for direct matches in the map\n",
    "    for full_name, code in state_map.items():\n",
    "        if full_name in state_input:\n",
    "            return code\n",
    "\n",
    "    # Fallback: check if the input is already a valid 2-letter code\n",
    "    potential_code = state_input.upper()[-2:]\n",
    "    if potential_code in state_map.values():\n",
    "        return potential_code\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "026c7f37-1765-49da-a337-3b6ebf12d678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Block 2: Load Data & Extract Grocery Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e77856d-0aa6-45b1-9a3e-c2cfbc68f76f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded: Grocery_data/us_cost_of_living_data\nLoaded: New_York_data_food/menu_data\nLoaded: UberEats/restaurants\nLoaded: Yelp Data/yelp_restaurants_california\nLoaded: Yelp Data/yelp_restaurants_hawaii\nLoaded: Yelp Data/yelp_restaurants_nevada\nLoaded: Yelp Data/yelp_restaurants_illinois\nLoaded: Yelp Data/yelp_restaurants_texas\nLoaded: Yelp Data/yelp_restaurants_new_york\nLoaded: Yelp Data/yelp_restaurants_michigan\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "# Iterate through folders and load all CSVs\n",
    "for folder in FOLDERS:\n",
    "    path = os.path.join(ROOT_PATH, folder)\n",
    "    if os.path.exists(path):\n",
    "        data[folder] = {}\n",
    "        # Glob patterns to find csvs\n",
    "        for f in glob.glob(os.path.join(path, \"*.csv\")):\n",
    "            key_name = os.path.basename(f).replace('.csv', '')\n",
    "            data[folder][key_name] = pd.read_csv(f)\n",
    "            print(f\"Loaded: {folder}/{key_name}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Warning: Path not found: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3983a0ea-ac96-4827-b0df-e9a162680e5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Index Map Ready ---\nStates with Index Data: 51\nNational Average Index: 101.26\n"
     ]
    }
   ],
   "source": [
    "# Load the Cost of Living data to build our Index Map\n",
    "df_col = data['Grocery_data']['us_cost_of_living_data'].copy()\n",
    "df_col['state_code'] = df_col['State'].apply(extract_state)\n",
    "\n",
    "# Create lookup dictionary: {'NY': 103.5, 'TX': 91.2, ...}\n",
    "grocery_index_map = dict(zip(df_col['state_code'], df_col['Grocery']))\n",
    "national_avg_index = df_col['Grocery'].mean()\n",
    "\n",
    "print(f\"--- Index Map Ready ---\")\n",
    "print(f\"States with Index Data: {len(grocery_index_map)}\")\n",
    "print(f\"National Average Index: {national_avg_index:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "894883a2-c8e1-4061-9923-032d4ada11f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Block 3: Prepare Restaurant Data & synthasize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a82c3b-da2d-47b0-a8c8-4f9bbc15f4e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing UberEats...\nProcessing Yelp...\nProcessing NY Menu Data...\n--- Data Merged ---\nSources: ['UberEats' 'Yelp' 'NY_Data']\nTotal Rows: 53777\nCost Stats:\ncount    53777.000000\nmean        15.122336\nstd          6.997311\nmin          5.160000\n25%         10.520000\n50%         13.030000\n75%         17.650000\nmax        138.152062\nName: target_cost, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. MERGE & CLEAN (ALL FORMATS HANDLED)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_target_cost(val):\n",
    "    \"\"\"\n",
    "    The Universal Translator:\n",
    "    Converts Uber ($$), Yelp ($11-30), and NY (Float) into a continuous dollar amount.\n",
    "    \"\"\"\n",
    "    s = str(val).strip()\n",
    "    \n",
    "    # CASE 1: YELP RANGES (Specific Text)\n",
    "    if '11-30' in s:\n",
    "        return np.round(np.random.uniform(11, 30), 2)\n",
    "    if 'Under 10' in s or 'Under $10' in s:\n",
    "        return np.round(np.random.uniform(5, 10), 2)\n",
    "    if '31-60' in s:\n",
    "        return np.round(np.random.uniform(31, 60), 2)\n",
    "    if 'Above 61' in s or 'Above $61' in s:\n",
    "        return np.round(np.random.uniform(61, 90), 2)\n",
    "        \n",
    "    # CASE 2: UBER SYMBOLS ($, $$, etc.)\n",
    "    # We check length or specific characters\n",
    "    if '$$$$' in s or '4' in s:\n",
    "        return np.round(np.random.uniform(60, 100), 2)\n",
    "    if '$$$' in s or '3' in s:\n",
    "        return np.round(np.random.uniform(31, 60), 2)\n",
    "    if '$$' in s or '2' in s:\n",
    "        return np.round(np.random.uniform(15, 30), 2)\n",
    "    if '$' in s or '1' in s:\n",
    "        return np.round(np.random.uniform(8, 15), 2)\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "# --- 1. PROCESS UBER EATS ---\n",
    "print(\"Processing UberEats...\")\n",
    "uber = data['UberEats']['restaurants'].copy()\n",
    "uber['source'] = 'UberEats'\n",
    "uber['state'] = uber['full_address'].apply(extract_state)\n",
    "uber = uber.rename(columns={'score': 'rating', 'ratings': 'review_count', 'category': 'cuisine'})\n",
    "\n",
    "# Apply the translator\n",
    "uber['target_cost'] = uber['price_range'].apply(parse_target_cost)\n",
    "\n",
    "# --- 2. PROCESS YELP ---\n",
    "print(\"Processing Yelp...\")\n",
    "yelp_dfs = []\n",
    "if 'Yelp Data' in data:\n",
    "    for name, df in data['Yelp Data'].items():\n",
    "        df = df.copy()\n",
    "        df['source'] = 'Yelp'\n",
    "        df['state'] = extract_state(name)\n",
    "        df = df.rename(columns={'aggregatedRating': 'rating', 'reviewCount': 'review_count'})\n",
    "        \n",
    "        # Check for the column we identified in EDA\n",
    "        p_col = 'priceRange' if 'priceRange' in df.columns else 'price_level'\n",
    "        if p_col in df.columns:\n",
    "            df['target_cost'] = df[p_col].apply(parse_target_cost)\n",
    "            yelp_dfs.append(df)\n",
    "\n",
    "# --- 3. PROCESS NY MENU DATA (ACTUAL PRICES) ---\n",
    "print(\"Processing NY Menu Data...\")\n",
    "ny_dfs = []\n",
    "if 'New_York_data_food' in data and 'menu_data' in data['New_York_data_food']:\n",
    "    df_ny = data['New_York_data_food']['menu_data'].copy()\n",
    "    \n",
    "    # Clean Prices (Regex to keep only numbers and dots)\n",
    "    df_ny['clean_price'] = df_ny['Price'].astype(str).str.replace(r'[^\\d.]', '', regex=True)\n",
    "    df_ny['clean_price'] = pd.to_numeric(df_ny['clean_price'], errors='coerce')\n",
    "    \n",
    "    # Aggregate: Meal Cost ‚âà 2.0 * Average Item\n",
    "    ny_grouped = df_ny.groupby('Restaurant')['clean_price'].mean().reset_index()\n",
    "    ny_grouped['target_cost'] = ny_grouped['clean_price'] * 2.0\n",
    "    \n",
    "    # Add metadata\n",
    "    ny_grouped['source'] = 'NY_Data'\n",
    "    ny_grouped['state'] = 'NY'\n",
    "    ny_grouped['rating'] = 4.0       \n",
    "    ny_grouped['review_count'] = 50  \n",
    "    ny_grouped['cuisine'] = 'Other' \n",
    "    \n",
    "    ny_dfs.append(ny_grouped)\n",
    "\n",
    "# --- 4. COMBINE & FINAL CLEAN ---\n",
    "all_dfs = [uber] + yelp_dfs + ny_dfs\n",
    "df_master = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Drop rows where parsing failed (NaN cost) or state is unknown\n",
    "df_master = df_master.dropna(subset=['target_cost', 'state'])\n",
    "df_master = df_master[df_master['state'] != 'Unknown']\n",
    "print(f\"--- Data Merged ---\")\n",
    "print(f\"Sources: {df_master['source'].unique()}\")\n",
    "print(f\"Total Rows: {len(df_master)}\")\n",
    "print(f\"Cost Stats:\\n{df_master['target_cost'].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ec471b5-489b-4f35-b21b-34b0c13e64f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- üìä Row Counts by State (Top 10) ---\nstate\nTX    24634\nVA     7812\nWA     7355\nWI     3648\nUT     2510\nNE     1303\nWV     1265\nAL      952\nMD      626\nNY      616\nName: count, dtype: int64\n\n--- üí∞ Average Meal Cost by State (Top 10 Most Expensive) ---\nstate\nNY    29.831697\nDC    28.490000\nHI    25.161971\nMI    24.854383\nIL    20.496734\nIA    20.193333\nVT    19.590680\nKS    19.105000\nWY    17.382395\nCO    17.340909\nName: target_cost, dtype: float64\n\n--- üìâ Average Meal Cost by State (Top 10 Cheapest) ---\nstate\nTN    13.808511\nNH    13.540000\nKY    13.513333\nOR    13.205699\nMA    13.104286\nGA    13.083056\nND    10.515000\nNM    10.497500\nME     9.525000\nSC     8.410000\nName: target_cost, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# VERIFICATION: STATE BREAKDOWN\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- üìä Row Counts by State (Top 10) ---\")\n",
    "print(df_master['state'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n--- üí∞ Average Meal Cost by State (Top 10 Most Expensive) ---\")\n",
    "# Group by state and get the average 'target_cost'\n",
    "state_costs = df_master.groupby('state')['target_cost'].mean().sort_values(ascending=False)\n",
    "print(state_costs.head(10))\n",
    "\n",
    "print(\"\\n--- üìâ Average Meal Cost by State (Top 10 Cheapest) ---\")\n",
    "print(state_costs.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44f2c95-3932-4989-b278-4de1c27f3c7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Synthesis Plan ---\nGoal: Ensure every state has ~45000 rows.\nSynthesizing data for 52 states.\n‚úÖ Synthesis Complete.\nTotal Rows: 2340101\nNew Distribution (Top 5):\nstate\nOR    45003\nFL    45003\nWI    45003\nWY    45003\nMI    45003\nName: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. MULTI-SOURCE SYNTHESIS (BALANCE THE STATES)\n",
    "# ==========================================\n",
    "\n",
    "# Configuration\n",
    "# We want every state to have at least this many rows to ensure the model treats them equally.\n",
    "TARGET_ROWS_PER_STATE = 45000 \n",
    "SAMPLE_BATCH_SIZE = 15000 # We'll pull 15k chunks from different sources\n",
    "\n",
    "# 1. Identify \"Rich\" vs \"Poor\" Data States\n",
    "state_counts = df_master['state'].value_counts()\n",
    "existing_states = set(df_master['state'].unique())\n",
    "all_index_states = set(grocery_index_map.keys())\n",
    "\n",
    "# Targets = Missing States OR Existing States with < 45k rows\n",
    "# (This ensures even NY with 616 rows gets boosted)\n",
    "targets_missing = all_index_states - existing_states\n",
    "targets_low_data = [s for s in existing_states if state_counts[s] < TARGET_ROWS_PER_STATE]\n",
    "final_targets = list(targets_missing) + targets_low_data\n",
    "\n",
    "# Sources we can steal data from (e.g. UberEats, Yelp, NY_Data)\n",
    "available_sources = df_master['source'].unique()\n",
    "\n",
    "print(f\"--- Synthesis Plan ---\")\n",
    "print(f\"Goal: Ensure every state has ~{TARGET_ROWS_PER_STATE} rows.\")\n",
    "print(f\"Synthesizing data for {len(final_targets)} states.\")\n",
    "\n",
    "synthetic_dfs = []\n",
    "\n",
    "for target_state in final_targets:\n",
    "    # Get Cost Index for the target state (e.g. FL = 100.5)\n",
    "    target_index = grocery_index_map.get(target_state, national_avg_index)\n",
    "    \n",
    "    # Check how many rows we already have (so we don't over-synthesize)\n",
    "    current_count = state_counts.get(target_state, 0)\n",
    "    needed = TARGET_ROWS_PER_STATE - current_count\n",
    "    \n",
    "    if needed <= 0: continue\n",
    "\n",
    "    # Distribute the \"needed\" rows across available sources\n",
    "    # If we need 40k rows and have 3 sources, we take ~13k from each\n",
    "    rows_per_source = int(needed / len(available_sources)) + 1\n",
    "    \n",
    "    for source_name in available_sources:\n",
    "        # 1. Get data for this source\n",
    "        source_data = df_master[df_master['source'] == source_name]\n",
    "        if source_data.empty: continue\n",
    "            \n",
    "        # 2. Pick the best \"Template\" within this source (State with most rows)\n",
    "        best_template_state = source_data['state'].value_counts().idxmax()\n",
    "        template_df = source_data[source_data['state'] == best_template_state]\n",
    "        \n",
    "        # 3. Calculate Price Ratio\n",
    "        template_index = grocery_index_map.get(best_template_state, national_avg_index)\n",
    "        ratio = target_index / template_index\n",
    "        \n",
    "        # 4. Sample Rows\n",
    "        # Pull random meals from the template\n",
    "        replace_flag = len(template_df) < rows_per_source\n",
    "        sample_rows = template_df.sample(n=rows_per_source, replace=replace_flag)\n",
    "        \n",
    "        # 5. Create Synthetic Rows\n",
    "        new_rows = sample_rows.copy()\n",
    "        new_rows['state'] = target_state\n",
    "        new_rows['target_cost'] = new_rows['target_cost'] * ratio\n",
    "        \n",
    "        # Tag as synthetic just in case we want to debug later\n",
    "        # new_rows['source'] = source_name # Keep original source name so model knows it's \"Yelp-style\" data\n",
    "        \n",
    "        synthetic_dfs.append(new_rows)\n",
    "\n",
    "# Merge\n",
    "if synthetic_dfs:\n",
    "    df_synthetic = pd.concat(synthetic_dfs, ignore_index=True)\n",
    "    df_master = pd.concat([df_master, df_synthetic], ignore_index=True)\n",
    "\n",
    "print(f\"‚úÖ Synthesis Complete.\")\n",
    "print(f\"Total Rows: {len(df_master)}\")\n",
    "print(f\"New Distribution (Top 5):\\n{df_master['state'].value_counts().head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3edde690-e8c7-46d1-a9d8-cc1c24ea3e04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- 1. QUANTITY CHECK (Goal: > 40k rows per state) ---\nMinimum Rows in any state: 45001\nMaximum Rows in any state: 45003\n‚úÖ SUCCESS: All states have sufficient data.\n\n--- 2. QUALITY CHECK (Goal: Different Prices per State) ---\n\nTop 5 Most Expensive States (Synthesized):\n            mean        std       min         max\nstate                                            \nHI     28.385883  17.116002  5.730000  174.191730\nAK     26.919450  15.994446  5.462161  166.049435\nVT     23.325412  13.865235  4.724506  143.624752\nCA     23.322645  14.220396  4.720115  143.491272\nCT     23.232455  14.012382  4.698161  142.823871\n\nTop 5 Cheapest States (Synthesized):\n            mean        std       min         max\nstate                                            \nVA     20.457340  12.638685  4.417149  134.281135\nMS     20.444633  12.282769  4.140529  125.871879\nUT     20.350689  12.117964  4.202000  127.740602\nAR     20.178948  12.206740  4.052713  123.202274\nTX     17.550978   9.991535  4.153701  126.272319\n\nSanity Check:\n   Hawaii Mean: $28.39\n   Mississippi Mean: $20.44\n‚úÖ SUCCESS: Price scaling logic is working (HI > MS).\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# VERIFICATION: QUANTITY & QUALITY\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- 1. QUANTITY CHECK (Goal: > 40k rows per state) ---\")\n",
    "state_counts = df_master['state'].value_counts()\n",
    "min_count = state_counts.min()\n",
    "max_count = state_counts.max()\n",
    "\n",
    "print(f\"Minimum Rows in any state: {min_count}\")\n",
    "print(f\"Maximum Rows in any state: {max_count}\")\n",
    "\n",
    "if min_count < 40000:\n",
    "    print(f\"‚ö†Ô∏è FAIL: Some states have less than 40k rows. Run Synthesis again.\")\n",
    "    print(state_counts.tail())\n",
    "else:\n",
    "    print(\"‚úÖ SUCCESS: All states have sufficient data.\")\n",
    "\n",
    "print(\"\\n--- 2. QUALITY CHECK (Goal: Different Prices per State) ---\")\n",
    "# We check the Average Price per state to ensure the Index Math worked.\n",
    "# Expensive states (HI, NY, CA) should have higher averages than cheap states (MS, AL).\n",
    "\n",
    "stats = df_master.groupby('state')['target_cost'].agg(['mean', 'std', 'min', 'max']).sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Expensive States (Synthesized):\")\n",
    "print(stats.head(5))\n",
    "\n",
    "print(\"\\nTop 5 Cheapest States (Synthesized):\")\n",
    "print(stats.tail(5))\n",
    "\n",
    "# Sanity Check: Is Hawaii (HI) more expensive than Mississippi (MS)?\n",
    "try:\n",
    "    hi_price = stats.loc['HI', 'mean']\n",
    "    ms_price = stats.loc['MS', 'mean']\n",
    "    print(f\"\\nSanity Check:\")\n",
    "    print(f\"   Hawaii Mean: ${hi_price:.2f}\")\n",
    "    print(f\"   Mississippi Mean: ${ms_price:.2f}\")\n",
    "    \n",
    "    if hi_price > ms_price:\n",
    "        print(\"‚úÖ SUCCESS: Price scaling logic is working (HI > MS).\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è FAIL: Prices look wrong. Check Index Logic.\")\n",
    "except KeyError:\n",
    "    print(\"‚ö†Ô∏è Could not find HI or MS to compare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcfd14a7-0b8c-4cd5-befd-15d872d1bc15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0a96d04-03b6-4c44-b129-d4f8571ba824",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Preparing Training Data ---\nTraining on 1872080 rows...\nFeatures: 72 columns\n‚úÖ Model Trained!\nR¬≤ Score: 0.4590 (1.0 is perfect)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. TRAIN XGBOOST MODEL\n",
    "# ==========================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "print(\"--- Preparing Training Data ---\")\n",
    "\n",
    "# 1. Feature Engineering: Clean Cuisine\n",
    "# Group rare cuisines into 'Other' to keep the model fast\n",
    "top_cuisines = df_master['cuisine'].value_counts().nlargest(20).index\n",
    "df_master['clean_cuisine'] = df_master['cuisine'].apply(lambda x: x if x in top_cuisines else 'Other')\n",
    "\n",
    "# 2. One-Hot Encoding\n",
    "# This converts 'state' and 'cuisine' into numbers the model can understand\n",
    "# It creates columns like: state_AL, state_NY, clean_cuisine_Pizza, clean_cuisine_Mexican\n",
    "X = pd.get_dummies(df_master[['state', 'clean_cuisine', 'rating', 'review_count']], drop_first=True)\n",
    "y = df_master['target_cost']\n",
    "\n",
    "# 3. Split Data (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training on {len(X_train)} rows...\")\n",
    "print(f\"Features: {X_train.shape[1]} columns\")\n",
    "\n",
    "# 4. Train Model\n",
    "# n_estimators=200: Number of trees (higher = smarter but slower)\n",
    "# learning_rate=0.05: How carefully it learns (lower = prevents overfitting)\n",
    "model = xgb.XGBRegressor(n_estimators=300, max_depth=7, learning_rate=0.05, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"‚úÖ Model Trained!\")\n",
    "print(f\"R¬≤ Score: {score:.4f} (1.0 is perfect)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd68c4b0-9e38-41c6-b886-351eb1888e56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Block 4: The Final Predictor (With Weekly Grocery Breakup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9f7e4b8-934f-4a1b-a8d1-385b8ab1d1c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nüìä PREDICTION: 7 Days in TX (Moderate Plan)\n   ---------------------------------------------\n   üë• Group:            1 Male, 0 Female\n   üèôÔ∏è  Local Index:      94.6 (Multiplier: 0.946x)\n   ---------------------------------------------\n   üõí GROCERIES (Local): $101.59\n       ‚Ü≥ National Base:  $107.39/week\n       ‚Ü≥ Local Cost:     $101.59/week\n   üçΩÔ∏è  RESTAURANTS:      $56.99\n       ‚Ü≥ Avg Meal:       $14.25 (Mexican)\n   =============================================\n   üí∞ TOTAL BUDGET:      $158.58\n\nüìä PREDICTION: 7 Days in NY (Liberal Plan)\n   ---------------------------------------------\n   üë• Group:            1 Male, 1 Female\n   üèôÔ∏è  Local Index:      103.5 (Multiplier: 1.035x)\n   ---------------------------------------------\n   üõí GROCERIES (Local): $254.57\n       ‚Ü≥ National Base:  $245.96/week\n       ‚Ü≥ Local Cost:     $254.57/week\n   üçΩÔ∏è  RESTAURANTS:      $126.15\n       ‚Ü≥ Avg Meal:       $15.77 (Italian)\n   =============================================\n   üí∞ TOTAL BUDGET:      $380.72\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. PREDICTION TOOL (FIXED & COMPLETE)\n",
    "# ==========================================\n",
    "\n",
    "# 1. DEFINE ARTIFACTS (Fixes the \"artifacts not defined\" error)\n",
    "# We pack the model and maps you just created into this dictionary.\n",
    "if 'model' in locals() and 'X_train' in locals():\n",
    "    artifacts = {\n",
    "        \"xgb_model\": model,\n",
    "        \"model_columns\": X_train.columns,\n",
    "        \"grocery_index_map\": grocery_index_map,\n",
    "        \"national_avg_index\": national_avg_index\n",
    "    }\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Error: Model not found. Please run Block 6 (Training) first.\")\n",
    "\n",
    "# 2. USDA FOOD PLAN DATA (From your image)\n",
    "GROCERY_PLANS = {\n",
    "    \"low\":      {\"male\": 371.0, \"female\": 323.0},\n",
    "    \"moderate\": {\"male\": 465.0, \"female\": 392.0},\n",
    "    \"liberal\":  {\"male\": 566.0, \"female\": 499.0}\n",
    "}\n",
    "\n",
    "# 3. DEFINE THE FUNCTION\n",
    "def predict_trip_breakdown(state_code, people, days, \n",
    "                           cuisine=\"American\", vibe_rating=4.5, \n",
    "                           eating_out_per_week=4,\n",
    "                           budget_level=\"moderate\"):\n",
    "    \"\"\"\n",
    "    Predicts vacation costs using:\n",
    "    1. XGBoost Model for Restaurants (trained on 2.2M rows).\n",
    "    2. USDA Food Plans for Groceries (Adjusted by State Index).\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- A. RESTAURANT PREDICTION ---\n",
    "    input_row = pd.DataFrame(0, index=[0], columns=artifacts['model_columns'])\n",
    "    input_row['rating'] = vibe_rating\n",
    "    input_row['review_count'] = 150 \n",
    "    \n",
    "    if f\"state_{state_code}\" in input_row.columns:\n",
    "        input_row[f\"state_{state_code}\"] = 1\n",
    "    if f\"clean_cuisine_{cuisine}\" in input_row.columns:\n",
    "        input_row[f\"clean_cuisine_{cuisine}\"] = 1\n",
    "        \n",
    "    predicted_meal_price = artifacts['xgb_model'].predict(input_row)[0]\n",
    "    predicted_meal_price = max(predicted_meal_price, 7.0) # Safety floor\n",
    "    \n",
    "    # --- B. GROCERY PREDICTION ---\n",
    "    \n",
    "    # 1. Determine Group Composition\n",
    "    if people == 1:\n",
    "        males = 1; females = 0\n",
    "    else:\n",
    "        males = people // 2\n",
    "        females = people - males\n",
    "        \n",
    "    # 2. Get Base National Monthly Cost\n",
    "    plan = GROCERY_PLANS.get(budget_level.lower(), GROCERY_PLANS[\"moderate\"])\n",
    "    monthly_base_national = (males * plan[\"male\"]) + (females * plan[\"female\"])\n",
    "    \n",
    "    # 3. Convert to Weekly\n",
    "    weekly_base_national = monthly_base_national / 4.33\n",
    "    \n",
    "    # 4. APPLY STATE INDEX (The Accuracy Step)\n",
    "    state_index = artifacts['grocery_index_map'].get(state_code, artifacts['national_avg_index'])\n",
    "    state_multiplier = state_index / 100.0\n",
    "    \n",
    "    weekly_grocery_local = weekly_base_national * state_multiplier\n",
    "    \n",
    "    # --- C. TOTAL CALCULATIONS ---\n",
    "    weeks = days / 7.0\n",
    "    \n",
    "    # Restaurant Total\n",
    "    total_restaurant = predicted_meal_price * eating_out_per_week * weeks * people\n",
    "    \n",
    "    # Grocery Total (Reduce if eating out > 5 times/week)\n",
    "    grocery_factor = 0.7 if eating_out_per_week > 5 else 1.0\n",
    "    total_grocery = weekly_grocery_local * weeks * grocery_factor\n",
    "    \n",
    "    grand_total = total_restaurant + total_grocery\n",
    "\n",
    "    # --- D. OUTPUT ---\n",
    "    print(f\"\\nüìä PREDICTION: {days} Days in {state_code} ({budget_level.title()} Plan)\")\n",
    "    print(f\"   ---------------------------------------------\")\n",
    "    print(f\"   üë• Group:            {males} Male, {females} Female\")\n",
    "    print(f\"   üèôÔ∏è  Local Index:      {state_index:.1f} (Multiplier: {state_multiplier:.3f}x)\")\n",
    "    print(f\"   ---------------------------------------------\")\n",
    "    print(f\"   üõí GROCERIES (Local): ${total_grocery:.2f}\")\n",
    "    print(f\"       ‚Ü≥ National Base:  ${weekly_base_national:.2f}/week\")\n",
    "    print(f\"       ‚Ü≥ Local Cost:     ${weekly_grocery_local:.2f}/week\")\n",
    "    print(f\"   üçΩÔ∏è  RESTAURANTS:      ${total_restaurant:.2f}\")\n",
    "    print(f\"       ‚Ü≥ Avg Meal:       ${predicted_meal_price:.2f} ({cuisine})\")\n",
    "    print(f\"   =============================================\")\n",
    "    print(f\"   üí∞ TOTAL BUDGET:      ${grand_total:.2f}\")\n",
    "\n",
    "# --- TEST IT NOW ---\n",
    "predict_trip_breakdown(\"TX\", people=1, days=7, budget_level=\"moderate\", cuisine=\"Mexican\")\n",
    "predict_trip_breakdown(\"NY\", people=2, days=7, budget_level=\"liberal\", cuisine=\"Italian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18b03818-6a90-42cd-b996-4864c5814561",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d0f13dc-d690-4f3a-9a4a-995dcc9f9a18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Successfully saved model artifacts to 'food_cost_predictor_v2.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1. Bundle all necessary \"Knowledge\" into one dictionary\n",
    "# We save X_train.columns because the laptop needs to know EXACTLY which dummy columns exist (e.g., 'state_TX', 'clean_cuisine_Pizza')\n",
    "artifacts = {\n",
    "    \"xgb_model\": model,\n",
    "    \"model_columns\": X_train.columns.tolist(),  # The exact list of columns the model expects\n",
    "    \"grocery_index_map\": grocery_index_map,      # The dictionary for grocery costs\n",
    "    \"state_map_helper\": state_map                # The dictionary to convert names to codes\n",
    "}\n",
    "\n",
    "# 2. Save to a single file\n",
    "filename = \"food_cost_predictor_v2.pkl\"\n",
    "joblib.dump(artifacts, filename)\n",
    "\n",
    "print(f\"‚úÖ Successfully saved model artifacts to '{filename}'\")\n",
    "\n",
    "# If you are in Google Colab, use this to download it to your machine:\n",
    "# from google.colab import files\n",
    "# files.download(filename)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "food_final",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
